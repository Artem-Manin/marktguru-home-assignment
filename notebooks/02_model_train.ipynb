{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b148d1",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ecdda",
   "metadata": {},
   "source": [
    "### Yolo model parameters\n",
    "\n",
    "**EPOCHS**: The number of times the entire training dataset is passed through the model during training. More epochs can help the model learn better, but too many can lead to overfitting.\n",
    "\n",
    "**IMG_SIZE** (image size): The target size (usually width and height in pixels) to which all training and inference images are resized. Larger sizes can improve detection accuracy but use more memory and computation.\n",
    "\n",
    "**BATCH** (batch size): The number of images the model processes at once before updating its internal parameters. A larger batch size can speed up training (if you have enough GPU memory) but may require more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5fc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_YAML = Path(\"../data/silver/\")  # point to your dataset.yaml\n",
    "BASE_MODEL = \"yolov8n-cls.pt\"\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 512\n",
    "FRACTION = 1\n",
    "BATCH = 16\n",
    "DEVICE = \"cpu\"\n",
    "PROJECT_PATH = Path(\"../runs/classify\")\n",
    "\n",
    "CLASSES = {\n",
    "    \"pizza\": 76,\n",
    "    \"spaghetti_bolognese\": 90,\n",
    "    \"spaghetti_carbonara\": 91,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8516651",
   "metadata": {},
   "source": [
    "### First run of the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b91827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/base_model\u001b[0m\n",
      "002620_76_pizza.jpg: pizza (0.99)\n",
      "002667_76_pizza.jpg: pizza (0.86)\n",
      "002673_76_pizza.jpg: pizza (1.00)\n",
      "002610_76_pizza.jpg: pizza (0.72)\n",
      "002675_76_pizza.jpg: pizza (0.96)\n",
      "002650_76_pizza.jpg: pizza (0.98)\n",
      "002577_76_pizza.jpg: pizza (0.96)\n",
      "002504_76_pizza.jpg: pizza (0.99)\n",
      "025088_90_spaghetti_bolognese.jpg: crayfish (0.91)\n",
      "025101_90_spaghetti_bolognese.jpg: carbonara (0.38)\n",
      "025187_90_spaghetti_bolognese.jpg: carbonara (0.80)\n",
      "025023_90_spaghetti_bolognese.jpg: plate (0.68)\n",
      "025036_90_spaghetti_bolognese.jpg: plate (0.29)\n",
      "025201_90_spaghetti_bolognese.jpg: carbonara (1.00)\n",
      "025011_90_spaghetti_bolognese.jpg: carbonara (1.00)\n",
      "025068_90_spaghetti_bolognese.jpg: plate (0.50)\n",
      "022289_91_spaghetti_carbonara.jpg: carbonara (0.95)\n",
      "022254_91_spaghetti_carbonara.jpg: carbonara (1.00)\n",
      "022257_91_spaghetti_carbonara.jpg: carbonara (0.99)\n",
      "022410_91_spaghetti_carbonara.jpg: carbonara (1.00)\n",
      "022473_91_spaghetti_carbonara.jpg: carbonara (1.00)\n",
      "022450_91_spaghetti_carbonara.jpg: carbonara (0.98)\n",
      "022428_91_spaghetti_carbonara.jpg: carbonara (0.98)\n",
      "022405_91_spaghetti_carbonara.jpg: carbonara (0.78)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(BASE_MODEL)\n",
    "random.seed(42)\n",
    "N = 8 \n",
    "subset = []\n",
    "for cls in CLASSES.keys():\n",
    "    cls_dir = Path(DATASET_YAML) / \"val\" / cls\n",
    "    all_imgs = list(cls_dir.glob(\"*.jpg\"))\n",
    "    if len(all_imgs) >= N:\n",
    "        subset.extend(random.sample(all_imgs, N))\n",
    "    else:\n",
    "        subset.extend(all_imgs)\n",
    "results = model.predict(source=subset, imgsz=IMG_SIZE, device=DEVICE, save=True, verbose=False, project=PROJECT_PATH, name=\"food101_base_model\",exist_ok=True)\n",
    "for r in results:\n",
    "    fname = Path(r.path).name\n",
    "    pred_class = r.names[r.probs.top1]\n",
    "    conf = r.probs.top1conf.item()\n",
    "    print(f\"{fname}: {pred_class} ({conf:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c288e2",
   "metadata": {},
   "source": [
    "Pizza and spaghetti carbonara are recognized almost perfectly.\n",
    "Spaghetti bolognese is missing as a class - confused often with carbonara."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f1299",
   "metadata": {},
   "source": [
    "### Fine-tune model with food101 data\n",
    "\n",
    "The complete set consists of 750 images for training and 250 images for validation in each of three classes.\n",
    "\n",
    "Eight models will be trained for each constellation of:\n",
    "- two epoch values: 20 and 50,\n",
    "- two images sizes: 224 (standard for Yolo) and 512 (images from Hugging Face)\n",
    "- two dataset lengths: 75 and 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take hours to run!!!\n",
    "model = YOLO(BASE_MODEL)\n",
    "EPOCHS_LIST   = [20, 50]\n",
    "EPOCHS_LIST   = [50]\n",
    "IMG_SIZE_LIST = [224,512]\n",
    "IMG_SIZE_LIST = [512]\n",
    "FRACTIONS     = [0.1, 1]\n",
    "for epochs in EPOCHS_LIST:\n",
    "    for img in IMG_SIZE_LIST:\n",
    "        for frac in FRACTIONS:\n",
    "            name = f\"food101_e{epochs}_img{img}_frac{frac}\"\n",
    "            print(f\"\\n▶️ {name}\")\n",
    "            t0 = time.time()\n",
    "            res = model.train(\n",
    "                data=str(DATASET_YAML),\n",
    "                epochs=epochs,\n",
    "                imgsz=img,\n",
    "                batch=BATCH,\n",
    "                device=DEVICE,\n",
    "                project=str(PROJECT_PATH),\n",
    "                name=name,\n",
    "                exist_ok=True,\n",
    "                fraction=frac,\n",
    "                verbose=False\n",
    "            )\n",
    "            runtime_min = round((time.time() - t0) / 60, 3)\n",
    "            (PROJECT_PATH / name / \"summary.json\").write_text(\n",
    "                json.dumps({\"runtime_min\": runtime_min}, ensure_ascii=False)\n",
    "            )\n",
    "            print(f\"⏱️ runtime: {runtime_min} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16ab2f",
   "metadata": {},
   "source": [
    "### Gather statistics of model training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c5550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "def pick_col(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols: return c\n",
    "    return None\n",
    "for run in sorted(PROJECT_PATH.glob(\"food101_e*_img*_frac*\")):\n",
    "    args_p     = run / \"args.yaml\"\n",
    "    results_p  = run / \"results.csv\"\n",
    "    summary_p  = run / \"summary.json\"\n",
    "    best_pt_p  = run / \"weights\" / \"best.pt\"\n",
    "    if not results_p.exists():\n",
    "        continue\n",
    "    args = {}\n",
    "    if args_p.exists():\n",
    "        args = yaml.safe_load(args_p.read_text())\n",
    "    df = pd.read_csv(results_p)\n",
    "    top1_col = pick_col(df.columns, [\"metrics/accuracy_top1\", \"top1\", \"val/top1\"])\n",
    "    if top1_col is None:\n",
    "        best_top1 = float(\"nan\")\n",
    "    else:\n",
    "        best_row_idx = df[top1_col].idxmax()\n",
    "        best_top1 = float(df.loc[best_row_idx, top1_col])\n",
    "    runtime_min = None\n",
    "    if summary_p.exists():\n",
    "        runtime_min = json.loads(summary_p.read_text()).get(\"runtime_min\")\n",
    "    rows.append({\n",
    "        \"run_dir\": str(run.resolve()),\n",
    "        \"epochs\": args.get(\"epochs\"),\n",
    "        \"img_size\": args.get(\"imgsz\") or args.get(\"img_size\"),\n",
    "        \"fraction\": args.get(\"fraction\"),\n",
    "        \"top1_acc_best\": round(best_top1, 4) if best_top1 == best_top1 else None,  # NaN guard\n",
    "        \"runtime_min\": runtime_min,\n",
    "        \"best_weights\": str(best_pt_p.resolve()) if best_pt_p.exists() else None,\n",
    "    })\n",
    "stats = pd.DataFrame(rows)\n",
    "stats_path = PROJECT_PATH / \"experiment_stats.csv\"\n",
    "stats.to_csv(stats_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4eb73_row0_col3, #T_4eb73_row7_col4 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "#T_4eb73_row0_col4, #T_4eb73_row3_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4eb73\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4eb73_level0_col0\" class=\"col_heading level0 col0\" >epochs</th>\n",
       "      <th id=\"T_4eb73_level0_col1\" class=\"col_heading level0 col1\" >img_size</th>\n",
       "      <th id=\"T_4eb73_level0_col2\" class=\"col_heading level0 col2\" >fraction</th>\n",
       "      <th id=\"T_4eb73_level0_col3\" class=\"col_heading level0 col3\" >top1_acc_best</th>\n",
       "      <th id=\"T_4eb73_level0_col4\" class=\"col_heading level0 col4\" >runtime_min</th>\n",
       "      <th id=\"T_4eb73_level0_col5\" class=\"col_heading level0 col5\" >model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4eb73_row0_col0\" class=\"data row0 col0\" >20</td>\n",
       "      <td id=\"T_4eb73_row0_col1\" class=\"data row0 col1\" >224</td>\n",
       "      <td id=\"T_4eb73_row0_col2\" class=\"data row0 col2\" >0.100000</td>\n",
       "      <td id=\"T_4eb73_row0_col3\" class=\"data row0 col3\" >0.333300</td>\n",
       "      <td id=\"T_4eb73_row0_col4\" class=\"data row0 col4\" >6.230000</td>\n",
       "      <td id=\"T_4eb73_row0_col5\" class=\"data row0 col5\" >food101_e20_img224_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4eb73_row1_col0\" class=\"data row1 col0\" >20</td>\n",
       "      <td id=\"T_4eb73_row1_col1\" class=\"data row1 col1\" >224</td>\n",
       "      <td id=\"T_4eb73_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "      <td id=\"T_4eb73_row1_col3\" class=\"data row1 col3\" >0.972000</td>\n",
       "      <td id=\"T_4eb73_row1_col4\" class=\"data row1 col4\" >28.919000</td>\n",
       "      <td id=\"T_4eb73_row1_col5\" class=\"data row1 col5\" >food101_e20_img224_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4eb73_row2_col0\" class=\"data row2 col0\" >20</td>\n",
       "      <td id=\"T_4eb73_row2_col1\" class=\"data row2 col1\" >512</td>\n",
       "      <td id=\"T_4eb73_row2_col2\" class=\"data row2 col2\" >0.100000</td>\n",
       "      <td id=\"T_4eb73_row2_col3\" class=\"data row2 col3\" >0.894700</td>\n",
       "      <td id=\"T_4eb73_row2_col4\" class=\"data row2 col4\" >28.893000</td>\n",
       "      <td id=\"T_4eb73_row2_col5\" class=\"data row2 col5\" >food101_e20_img512_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4eb73_row3_col0\" class=\"data row3 col0\" >20</td>\n",
       "      <td id=\"T_4eb73_row3_col1\" class=\"data row3 col1\" >512</td>\n",
       "      <td id=\"T_4eb73_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_4eb73_row3_col3\" class=\"data row3 col3\" >0.980000</td>\n",
       "      <td id=\"T_4eb73_row3_col4\" class=\"data row3 col4\" >158.982000</td>\n",
       "      <td id=\"T_4eb73_row3_col5\" class=\"data row3 col5\" >food101_e20_img512_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4eb73_row4_col0\" class=\"data row4 col0\" >50</td>\n",
       "      <td id=\"T_4eb73_row4_col1\" class=\"data row4 col1\" >224</td>\n",
       "      <td id=\"T_4eb73_row4_col2\" class=\"data row4 col2\" >0.100000</td>\n",
       "      <td id=\"T_4eb73_row4_col3\" class=\"data row4 col3\" >0.917300</td>\n",
       "      <td id=\"T_4eb73_row4_col4\" class=\"data row4 col4\" >14.628000</td>\n",
       "      <td id=\"T_4eb73_row4_col5\" class=\"data row4 col5\" >food101_e50_img224_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4eb73_row5_col0\" class=\"data row5 col0\" >50</td>\n",
       "      <td id=\"T_4eb73_row5_col1\" class=\"data row5 col1\" >224</td>\n",
       "      <td id=\"T_4eb73_row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "      <td id=\"T_4eb73_row5_col3\" class=\"data row5 col3\" >0.976000</td>\n",
       "      <td id=\"T_4eb73_row5_col4\" class=\"data row5 col4\" >73.864000</td>\n",
       "      <td id=\"T_4eb73_row5_col5\" class=\"data row5 col5\" >food101_e50_img224_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4eb73_row6_col0\" class=\"data row6 col0\" >50</td>\n",
       "      <td id=\"T_4eb73_row6_col1\" class=\"data row6 col1\" >512</td>\n",
       "      <td id=\"T_4eb73_row6_col2\" class=\"data row6 col2\" >0.100000</td>\n",
       "      <td id=\"T_4eb73_row6_col3\" class=\"data row6 col3\" >0.940000</td>\n",
       "      <td id=\"T_4eb73_row6_col4\" class=\"data row6 col4\" >71.703000</td>\n",
       "      <td id=\"T_4eb73_row6_col5\" class=\"data row6 col5\" >food101_e50_img512_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4eb73_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4eb73_row7_col0\" class=\"data row7 col0\" >50</td>\n",
       "      <td id=\"T_4eb73_row7_col1\" class=\"data row7 col1\" >512</td>\n",
       "      <td id=\"T_4eb73_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_4eb73_row7_col3\" class=\"data row7 col3\" >0.970700</td>\n",
       "      <td id=\"T_4eb73_row7_col4\" class=\"data row7 col4\" >420.000000</td>\n",
       "      <td id=\"T_4eb73_row7_col5\" class=\"data row7 col5\" >food101_e50_img512_frac1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b1574b3e750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(PROJECT_PATH / \"experiment_stats.csv\")\n",
    "stats[\"model\"] = stats[\"best_weights\"].apply(lambda p: Path(p).parent.parent.name)\n",
    "stats_subset = stats.drop(columns=[\"run_dir\", \"best_weights\"])\n",
    "(\n",
    "    stats_subset.style\n",
    "    .highlight_max(subset=['top1_acc_best'], color='lightgreen')\n",
    "    .highlight_max(subset=['runtime_min'], color='lightcoral')\n",
    "    .highlight_min(subset=['top1_acc_best'], color='lightcoral')\n",
    "    .highlight_min(subset=['runtime_min'], color='lightgreen')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b37c5b",
   "metadata": {},
   "source": [
    "### Predict custom uploaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/classify/food101_e20_img224_frac1/weights/best.pt\")\n",
    "model.predict(\n",
    "    source=Path(DATASET_YAML) / \"upload\",\n",
    "    imgsz=224,\n",
    "    device=\"cpu\",\n",
    "    save=True,\n",
    "    project=PROJECT_PATH,\n",
    "    name=\"food101_predict_upload\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
