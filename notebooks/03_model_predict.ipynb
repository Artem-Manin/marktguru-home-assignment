{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b148d1",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5fc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_YAML = Path(\"../data/silver/\")  # point to your dataset.yaml\n",
    "BASE_MODEL = \"yolov8n-cls.pt\"\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 512\n",
    "FRACTION = 1\n",
    "BATCH = 16\n",
    "DEVICE = \"cpu\"\n",
    "PROJECT_PATH = Path(\"../runs/classify\")\n",
    "\n",
    "CLASSES = {\n",
    "    \"pizza\": 76,\n",
    "    \"spaghetti_bolognese\": 90,\n",
    "    \"spaghetti_carbonara\": 91,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16ab2f",
   "metadata": {},
   "source": [
    "### Gather statistics of model training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c5550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "def pick_col(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols: return c\n",
    "    return None\n",
    "for run in sorted(PROJECT_PATH.glob(\"food101_e*_img*_frac*\")):\n",
    "    args_p     = run / \"args.yaml\"\n",
    "    results_p  = run / \"results.csv\"\n",
    "    summary_p  = run / \"summary.json\"\n",
    "    best_pt_p  = run / \"weights\" / \"best.pt\"\n",
    "    if not results_p.exists():\n",
    "        continue\n",
    "    args = {}\n",
    "    if args_p.exists():\n",
    "        args = yaml.safe_load(args_p.read_text())\n",
    "    df = pd.read_csv(results_p)\n",
    "    top1_col = pick_col(df.columns, [\"metrics/accuracy_top1\", \"top1\", \"val/top1\"])\n",
    "    if top1_col is None:\n",
    "        best_top1 = float(\"nan\")\n",
    "    else:\n",
    "        best_row_idx = df[top1_col].idxmax()\n",
    "        best_top1 = float(df.loc[best_row_idx, top1_col])\n",
    "    runtime_min = None\n",
    "    if summary_p.exists():\n",
    "        runtime_min = json.loads(summary_p.read_text()).get(\"runtime_min\")\n",
    "    rows.append({\n",
    "        \"run_dir\": str(run.resolve()),\n",
    "        \"epochs\": args.get(\"epochs\"),\n",
    "        \"img_size\": args.get(\"imgsz\") or args.get(\"img_size\"),\n",
    "        \"fraction\": args.get(\"fraction\"),\n",
    "        \"top1_acc_best\": round(best_top1, 4) if best_top1 == best_top1 else None,  # NaN guard\n",
    "        \"runtime_min\": runtime_min,\n",
    "        \"best_weights\": str(best_pt_p.resolve()) if best_pt_p.exists() else None,\n",
    "    })\n",
    "stats = pd.DataFrame(rows)\n",
    "stats_path = PROJECT_PATH / \"experiment_stats.csv\"\n",
    "stats.to_csv(stats_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b1bc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f303e_row0_col3, #T_f303e_row7_col4 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "#T_f303e_row0_col4, #T_f303e_row3_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f303e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f303e_level0_col0\" class=\"col_heading level0 col0\" >epochs</th>\n",
       "      <th id=\"T_f303e_level0_col1\" class=\"col_heading level0 col1\" >img_size</th>\n",
       "      <th id=\"T_f303e_level0_col2\" class=\"col_heading level0 col2\" >fraction</th>\n",
       "      <th id=\"T_f303e_level0_col3\" class=\"col_heading level0 col3\" >top1_acc_best</th>\n",
       "      <th id=\"T_f303e_level0_col4\" class=\"col_heading level0 col4\" >runtime_min</th>\n",
       "      <th id=\"T_f303e_level0_col5\" class=\"col_heading level0 col5\" >model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f303e_row0_col0\" class=\"data row0 col0\" >20</td>\n",
       "      <td id=\"T_f303e_row0_col1\" class=\"data row0 col1\" >224</td>\n",
       "      <td id=\"T_f303e_row0_col2\" class=\"data row0 col2\" >0.100000</td>\n",
       "      <td id=\"T_f303e_row0_col3\" class=\"data row0 col3\" >0.333300</td>\n",
       "      <td id=\"T_f303e_row0_col4\" class=\"data row0 col4\" >6.230000</td>\n",
       "      <td id=\"T_f303e_row0_col5\" class=\"data row0 col5\" >food101_e20_img224_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f303e_row1_col0\" class=\"data row1 col0\" >20</td>\n",
       "      <td id=\"T_f303e_row1_col1\" class=\"data row1 col1\" >224</td>\n",
       "      <td id=\"T_f303e_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "      <td id=\"T_f303e_row1_col3\" class=\"data row1 col3\" >0.972000</td>\n",
       "      <td id=\"T_f303e_row1_col4\" class=\"data row1 col4\" >28.919000</td>\n",
       "      <td id=\"T_f303e_row1_col5\" class=\"data row1 col5\" >food101_e20_img224_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f303e_row2_col0\" class=\"data row2 col0\" >20</td>\n",
       "      <td id=\"T_f303e_row2_col1\" class=\"data row2 col1\" >512</td>\n",
       "      <td id=\"T_f303e_row2_col2\" class=\"data row2 col2\" >0.100000</td>\n",
       "      <td id=\"T_f303e_row2_col3\" class=\"data row2 col3\" >0.894700</td>\n",
       "      <td id=\"T_f303e_row2_col4\" class=\"data row2 col4\" >28.893000</td>\n",
       "      <td id=\"T_f303e_row2_col5\" class=\"data row2 col5\" >food101_e20_img512_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f303e_row3_col0\" class=\"data row3 col0\" >20</td>\n",
       "      <td id=\"T_f303e_row3_col1\" class=\"data row3 col1\" >512</td>\n",
       "      <td id=\"T_f303e_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_f303e_row3_col3\" class=\"data row3 col3\" >0.980000</td>\n",
       "      <td id=\"T_f303e_row3_col4\" class=\"data row3 col4\" >158.982000</td>\n",
       "      <td id=\"T_f303e_row3_col5\" class=\"data row3 col5\" >food101_e20_img512_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f303e_row4_col0\" class=\"data row4 col0\" >50</td>\n",
       "      <td id=\"T_f303e_row4_col1\" class=\"data row4 col1\" >224</td>\n",
       "      <td id=\"T_f303e_row4_col2\" class=\"data row4 col2\" >0.100000</td>\n",
       "      <td id=\"T_f303e_row4_col3\" class=\"data row4 col3\" >0.917300</td>\n",
       "      <td id=\"T_f303e_row4_col4\" class=\"data row4 col4\" >14.628000</td>\n",
       "      <td id=\"T_f303e_row4_col5\" class=\"data row4 col5\" >food101_e50_img224_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f303e_row5_col0\" class=\"data row5 col0\" >50</td>\n",
       "      <td id=\"T_f303e_row5_col1\" class=\"data row5 col1\" >224</td>\n",
       "      <td id=\"T_f303e_row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "      <td id=\"T_f303e_row5_col3\" class=\"data row5 col3\" >0.976000</td>\n",
       "      <td id=\"T_f303e_row5_col4\" class=\"data row5 col4\" >73.864000</td>\n",
       "      <td id=\"T_f303e_row5_col5\" class=\"data row5 col5\" >food101_e50_img224_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f303e_row6_col0\" class=\"data row6 col0\" >50</td>\n",
       "      <td id=\"T_f303e_row6_col1\" class=\"data row6 col1\" >512</td>\n",
       "      <td id=\"T_f303e_row6_col2\" class=\"data row6 col2\" >0.100000</td>\n",
       "      <td id=\"T_f303e_row6_col3\" class=\"data row6 col3\" >0.940000</td>\n",
       "      <td id=\"T_f303e_row6_col4\" class=\"data row6 col4\" >71.703000</td>\n",
       "      <td id=\"T_f303e_row6_col5\" class=\"data row6 col5\" >food101_e50_img512_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f303e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f303e_row7_col0\" class=\"data row7 col0\" >50</td>\n",
       "      <td id=\"T_f303e_row7_col1\" class=\"data row7 col1\" >512</td>\n",
       "      <td id=\"T_f303e_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_f303e_row7_col3\" class=\"data row7 col3\" >0.970700</td>\n",
       "      <td id=\"T_f303e_row7_col4\" class=\"data row7 col4\" >420.000000</td>\n",
       "      <td id=\"T_f303e_row7_col5\" class=\"data row7 col5\" >food101_e50_img512_frac1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x760bd4d2ba50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(PROJECT_PATH / \"experiment_stats.csv\")\n",
    "stats[\"model\"] = stats[\"best_weights\"].apply(lambda p: Path(p).parent.parent.name)\n",
    "stats_subset = stats.drop(columns=[\"run_dir\", \"best_weights\"])\n",
    "(\n",
    "    stats_subset.style\n",
    "    .highlight_max(subset=['top1_acc_best'], color='lightgreen')\n",
    "    .highlight_min(subset=['top1_acc_best'], color='lightcoral')\n",
    "    .highlight_max(subset=['runtime_min'], color='lightcoral')\n",
    "    .highlight_min(subset=['runtime_min'], color='lightgreen')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d120f",
   "metadata": {},
   "source": [
    "### Inaccurate and long-training models\n",
    "\n",
    "1. A model with minimum parameters `food101_e20_img224_frac0.1` shows a very poor accuracy result - `0.33`<br>\n",
    "[Confusion matrix](../runs/classify/food101_e20_img224_frac0.1/confusion_matrix_normalized.png) shows that actually all the dishes were put into one class - pizza.<br>\n",
    "A very low runtime should not distract here - we will not use this model and remove from futher analysis.\n",
    "2. On the other side of the spectrum, there are models with an excellent accuracy (`> 97%`), but with also the longest runtime (`> 2 hours`):\n",
    "    - `food101_e20_img512_frac1`\n",
    "    - `food101_e50_img512_frac1`\n",
    "\n",
    "    Let's remove them as well.\n",
    "\n",
    "3. The remaining five models lie in the range `89-97%` for accuracy and `14-74 minutes` for runtime, which is fully acceptable.\n",
    "4. Let's add for them some efficiency metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40dd9740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61510_row2_col7 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_61510_row3_col7, #T_61510_row4_col7 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61510\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61510_level0_col0\" class=\"col_heading level0 col0\" >epochs</th>\n",
       "      <th id=\"T_61510_level0_col1\" class=\"col_heading level0 col1\" >img_size</th>\n",
       "      <th id=\"T_61510_level0_col2\" class=\"col_heading level0 col2\" >fraction</th>\n",
       "      <th id=\"T_61510_level0_col3\" class=\"col_heading level0 col3\" >top1_acc_best</th>\n",
       "      <th id=\"T_61510_level0_col4\" class=\"col_heading level0 col4\" >runtime_min</th>\n",
       "      <th id=\"T_61510_level0_col5\" class=\"col_heading level0 col5\" >model</th>\n",
       "      <th id=\"T_61510_level0_col6\" class=\"col_heading level0 col6\" >efficiency</th>\n",
       "      <th id=\"T_61510_level0_col7\" class=\"col_heading level0 col7\" >efficiency_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61510_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_61510_row0_col0\" class=\"data row0 col0\" >20</td>\n",
       "      <td id=\"T_61510_row0_col1\" class=\"data row0 col1\" >224</td>\n",
       "      <td id=\"T_61510_row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "      <td id=\"T_61510_row0_col3\" class=\"data row0 col3\" >0.972000</td>\n",
       "      <td id=\"T_61510_row0_col4\" class=\"data row0 col4\" >28.919000</td>\n",
       "      <td id=\"T_61510_row0_col5\" class=\"data row0 col5\" >food101_e20_img224_frac1</td>\n",
       "      <td id=\"T_61510_row0_col6\" class=\"data row0 col6\" >0.033611</td>\n",
       "      <td id=\"T_61510_row0_col7\" class=\"data row0 col7\" >0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61510_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_61510_row1_col0\" class=\"data row1 col0\" >20</td>\n",
       "      <td id=\"T_61510_row1_col1\" class=\"data row1 col1\" >512</td>\n",
       "      <td id=\"T_61510_row1_col2\" class=\"data row1 col2\" >0.100000</td>\n",
       "      <td id=\"T_61510_row1_col3\" class=\"data row1 col3\" >0.894700</td>\n",
       "      <td id=\"T_61510_row1_col4\" class=\"data row1 col4\" >28.893000</td>\n",
       "      <td id=\"T_61510_row1_col5\" class=\"data row1 col5\" >food101_e20_img512_frac0.1</td>\n",
       "      <td id=\"T_61510_row1_col6\" class=\"data row1 col6\" >0.030966</td>\n",
       "      <td id=\"T_61510_row1_col7\" class=\"data row1 col7\" >0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61510_level0_row2\" class=\"row_heading level0 row2\" >4</th>\n",
       "      <td id=\"T_61510_row2_col0\" class=\"data row2 col0\" >50</td>\n",
       "      <td id=\"T_61510_row2_col1\" class=\"data row2 col1\" >224</td>\n",
       "      <td id=\"T_61510_row2_col2\" class=\"data row2 col2\" >0.100000</td>\n",
       "      <td id=\"T_61510_row2_col3\" class=\"data row2 col3\" >0.917300</td>\n",
       "      <td id=\"T_61510_row2_col4\" class=\"data row2 col4\" >14.628000</td>\n",
       "      <td id=\"T_61510_row2_col5\" class=\"data row2 col5\" >food101_e50_img224_frac0.1</td>\n",
       "      <td id=\"T_61510_row2_col6\" class=\"data row2 col6\" >0.062709</td>\n",
       "      <td id=\"T_61510_row2_col7\" class=\"data row2 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61510_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "      <td id=\"T_61510_row3_col0\" class=\"data row3 col0\" >50</td>\n",
       "      <td id=\"T_61510_row3_col1\" class=\"data row3 col1\" >224</td>\n",
       "      <td id=\"T_61510_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_61510_row3_col3\" class=\"data row3 col3\" >0.976000</td>\n",
       "      <td id=\"T_61510_row3_col4\" class=\"data row3 col4\" >73.864000</td>\n",
       "      <td id=\"T_61510_row3_col5\" class=\"data row3 col5\" >food101_e50_img224_frac1</td>\n",
       "      <td id=\"T_61510_row3_col6\" class=\"data row3 col6\" >0.013213</td>\n",
       "      <td id=\"T_61510_row3_col7\" class=\"data row3 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61510_level0_row4\" class=\"row_heading level0 row4\" >6</th>\n",
       "      <td id=\"T_61510_row4_col0\" class=\"data row4 col0\" >50</td>\n",
       "      <td id=\"T_61510_row4_col1\" class=\"data row4 col1\" >512</td>\n",
       "      <td id=\"T_61510_row4_col2\" class=\"data row4 col2\" >0.100000</td>\n",
       "      <td id=\"T_61510_row4_col3\" class=\"data row4 col3\" >0.940000</td>\n",
       "      <td id=\"T_61510_row4_col4\" class=\"data row4 col4\" >71.703000</td>\n",
       "      <td id=\"T_61510_row4_col5\" class=\"data row4 col5\" >food101_e50_img512_frac0.1</td>\n",
       "      <td id=\"T_61510_row4_col6\" class=\"data row4 col6\" >0.013110</td>\n",
       "      <td id=\"T_61510_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x760bd3d315d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_filt = stats_subset[\n",
    "    ~stats_subset[\"model\"].isin([\n",
    "        \"food101_e20_img224_frac0.1\",\n",
    "        \"food101_e20_img512_frac1\",\n",
    "        \"food101_e50_img512_frac1\"\n",
    "    ])\n",
    "].copy() \n",
    "stats_filt[\"efficiency\"] = stats_filt[\"top1_acc_best\"] / stats_filt[\"runtime_min\"]\n",
    "eff = stats_filt[\"efficiency\"]\n",
    "stats_filt[\"efficiency_norm\"] = ((eff - eff.min()) / (eff.max() - eff.min())).round(2)\n",
    "(\n",
    "    stats_filt.style\n",
    "    .highlight_max(subset=['efficiency_norm'], color='lightgreen')\n",
    "    .highlight_min(subset=['efficiency_norm'], color='lightcoral')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932efe6",
   "metadata": {},
   "source": [
    "`food101_e50_img224_frac0.1` seems to be the most efficient, probably meaning that number of epochs is more important than the image size and the size of the dataset to train and validate.<br>\n",
    "It has decent `91.73%` accuracy while having training runtime of only `15 minutes`.\n",
    "\n",
    "We will check the influence of each parameter below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d223c",
   "metadata": {},
   "source": [
    "### Impact of each parameter change on precision and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc21387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>target</th>\n",
       "      <th>from→to</th>\n",
       "      <th>abs_change</th>\n",
       "      <th>rel_change_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epochs</td>\n",
       "      <td>runtime_min</td>\n",
       "      <td>20→50</td>\n",
       "      <td>43.8775</td>\n",
       "      <td>151.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fraction</td>\n",
       "      <td>runtime_min</td>\n",
       "      <td>0.1→1.0</td>\n",
       "      <td>59.2360</td>\n",
       "      <td>404.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_size</td>\n",
       "      <td>runtime_min</td>\n",
       "      <td>224→512</td>\n",
       "      <td>57.0750</td>\n",
       "      <td>390.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>epochs</td>\n",
       "      <td>top1_acc_best</td>\n",
       "      <td>20→50</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>2.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fraction</td>\n",
       "      <td>top1_acc_best</td>\n",
       "      <td>0.1→1.0</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>6.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img_size</td>\n",
       "      <td>top1_acc_best</td>\n",
       "      <td>224→512</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>2.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      param         target  from→to  abs_change  rel_change_%\n",
       "0    epochs    runtime_min    20→50     43.8775       151.795\n",
       "1  fraction    runtime_min  0.1→1.0     59.2360       404.950\n",
       "2  img_size    runtime_min  224→512     57.0750       390.180\n",
       "3    epochs  top1_acc_best    20→50      0.0246         2.735\n",
       "4  fraction  top1_acc_best  0.1→1.0      0.0587         6.400\n",
       "5  img_size  top1_acc_best  224→512      0.0227         2.470"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = stats_filt.copy()\n",
    "\n",
    "comparisons = []\n",
    "\n",
    "# Epochs effect (control img_size + fraction)\n",
    "for (img, frac), group in df.groupby([\"img_size\", \"fraction\"]):\n",
    "    if {20, 50}.issubset(set(group[\"epochs\"])):\n",
    "        base = group[group[\"epochs\"] == 20].iloc[0]\n",
    "        alt  = group[group[\"epochs\"] == 50].iloc[0]\n",
    "        for target in [\"top1_acc_best\", \"runtime_min\"]:\n",
    "            diff_abs = alt[target] - base[target]\n",
    "            diff_rel = diff_abs / base[target] * 100\n",
    "            comparisons.append({\n",
    "                \"param\": \"epochs\",\n",
    "                \"control\": f\"img={img}, frac={frac}\",\n",
    "                \"from→to\": \"20→50\",\n",
    "                \"target\": target,\n",
    "                \"abs_change\": round(diff_abs, 4),\n",
    "                \"rel_change_%\": round(diff_rel, 2)\n",
    "            })\n",
    "\n",
    "# Img_size effect (control epochs + fraction)\n",
    "for (ep, frac), group in df.groupby([\"epochs\", \"fraction\"]):\n",
    "    if {224, 512}.issubset(set(group[\"img_size\"])):\n",
    "        base = group[group[\"img_size\"] == 224].iloc[0]\n",
    "        alt  = group[group[\"img_size\"] == 512].iloc[0]\n",
    "        for target in [\"top1_acc_best\", \"runtime_min\"]:\n",
    "            diff_abs = alt[target] - base[target]\n",
    "            diff_rel = diff_abs / base[target] * 100\n",
    "            comparisons.append({\n",
    "                \"param\": \"img_size\",\n",
    "                \"control\": f\"epochs={ep}, frac={frac}\",\n",
    "                \"from→to\": \"224→512\",\n",
    "                \"target\": target,\n",
    "                \"abs_change\": round(diff_abs, 4),\n",
    "                \"rel_change_%\": round(diff_rel, 2)\n",
    "            })\n",
    "\n",
    "# Fraction effect (control epochs + img_size)\n",
    "for (ep, img), group in df.groupby([\"epochs\", \"img_size\"]):\n",
    "    if {0.1, 1.0}.issubset(set(group[\"fraction\"])):\n",
    "        base = group[group[\"fraction\"] == 0.1].iloc[0]\n",
    "        alt  = group[group[\"fraction\"] == 1.0].iloc[0]\n",
    "        for target in [\"top1_acc_best\", \"runtime_min\"]:\n",
    "            diff_abs = alt[target] - base[target]\n",
    "            diff_rel = diff_abs / base[target] * 100\n",
    "            comparisons.append({\n",
    "                \"param\": \"fraction\",\n",
    "                \"control\": f\"epochs={ep}, img={img}\",\n",
    "                \"from→to\": \"0.1→1.0\",\n",
    "                \"target\": target,\n",
    "                \"abs_change\": round(diff_abs, 4),\n",
    "                \"rel_change_%\": round(diff_rel, 2)\n",
    "            })\n",
    "\n",
    "comp_df = pd.DataFrame(comparisons)\n",
    "comp_df = comp_df.sort_values(by=[\"param\", \"target\", \"control\"]).reset_index(drop=True)\n",
    "summary = (\n",
    "    comp_df\n",
    "    .groupby([\"param\", \"target\", \"from→to\"], as_index=False)[[\"abs_change\", \"rel_change_%\"]]\n",
    "    .mean()\n",
    "    .round(4)\n",
    ")\n",
    "summary.sort_values(by=[\"target\", \"param\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a2740",
   "metadata": {},
   "source": [
    "With this statistics, all parameters tend to have certain impact on both accuracy and runtime, without any of them to stand out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b37c5b",
   "metadata": {},
   "source": [
    "### Predict custom uploaded images\n",
    "For prediction we will take three models:\n",
    "- food101_e50_img224_frac0.1: the most efficient with accuracy of `91.73%`\n",
    "- food101_e50_img224_frac1: best accuracy of `97.60%`\n",
    "- food101_e20_img512_frac0.1: lowest accuracy of `89.47%`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c1a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 models\n",
      "▶️ Predicting with food101_e50_img224_frac0.1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e50_img224_frac0.1\u001b[0m\n",
      "✅ Labeled predictions sorted to ../runs/classify/sorted_food101_e50_img224_frac0.1\n",
      "▶️ Predicting with food101_e50_img224_frac1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e50_img224_frac1\u001b[0m\n",
      "✅ Labeled predictions sorted to ../runs/classify/sorted_food101_e50_img224_frac1\n",
      "▶️ Predicting with food101_e20_img512_frac0.1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e20_img512_frac0.1\u001b[0m\n",
      "✅ Labeled predictions sorted to ../runs/classify/sorted_food101_e20_img512_frac0.1\n"
     ]
    }
   ],
   "source": [
    "upload_dir = Path(DATASET_YAML) / \"upload\"\n",
    "selected_models = [\n",
    "    \"food101_e50_img224_frac0.1\",  # most efficient\n",
    "    \"food101_e50_img224_frac1\",    # best accuracy\n",
    "    \"food101_e20_img512_frac0.1\"   # lowest accuracy\n",
    "]\n",
    "models = [PROJECT_PATH / m / \"weights\" / \"best.pt\" for m in selected_models]\n",
    "print(f\"Found {len(models)} models\")\n",
    "\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "\n",
    "for m in models:\n",
    "    exp_name = m.parent.parent.name  # e.g. food101_e20_img224_frac0.1\n",
    "    print(f\"▶️ Predicting with {exp_name}\")\n",
    "\n",
    "    # parse imgsz from name (expects \"..._img{N}_...\")\n",
    "    try:\n",
    "        img_size = int(exp_name.split(\"_img\")[1].split(\"_\")[0])\n",
    "    except Exception:\n",
    "        img_size = 224\n",
    "\n",
    "    model = YOLO(m)\n",
    "    results = model.predict(\n",
    "        source=upload_dir,\n",
    "        imgsz=img_size,\n",
    "        device=\"cpu\",\n",
    "        save=True,              # writes labeled images into project/name/\n",
    "        project=PROJECT_PATH,\n",
    "        name=f\"predict_{exp_name}\",\n",
    "        exist_ok=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # sort the **labeled** images into class folders\n",
    "    sorted_dir = PROJECT_PATH / f\"sorted_{exp_name}\"\n",
    "    sorted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for r in results:\n",
    "        pred_class = r.names[r.probs.top1]\n",
    "\n",
    "        # where Ultralytics saved this labeled image\n",
    "        save_dir = Path(r.save_dir)                # predict folder for this run\n",
    "        src_name = Path(r.path).name               # original filename\n",
    "        labeled_path = save_dir / src_name         # typical case (same name)\n",
    "\n",
    "        if not labeled_path.exists():\n",
    "            # fallback: find any image starting with the same stem (covers suffix variants)\n",
    "            stem = Path(src_name).stem\n",
    "            cand = []\n",
    "            for ext in IMAGE_EXTS:\n",
    "                cand += list(save_dir.glob(f\"{stem}*{ext}\"))\n",
    "            labeled_path = cand[0] if cand else None\n",
    "\n",
    "        # target folder by predicted class\n",
    "        target_dir = sorted_dir / pred_class\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if labeled_path and labeled_path.exists():\n",
    "            shutil.copy(labeled_path, target_dir / labeled_path.name)\n",
    "        else:\n",
    "            # fallback: copy original if labeled not found\n",
    "            shutil.copy(r.path, target_dir / src_name)\n",
    "\n",
    "    print(f\"✅ Labeled predictions sorted to {sorted_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e3202",
   "metadata": {},
   "source": [
    "### aaa\n",
    "\n",
    "![](img/sorted_food101_e20_img512_frac0.1.jpg)\n",
    "![](notebooks/img/sorted_food101_e20_img512_frac0.1.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3611134",
   "metadata": {},
   "source": [
    "### food101_e50_img224_frac0.1: the most efficient with accuracy of `91.73%`\n",
    "1/15 image are classified incorrectly:\n",
    "\n",
    "![](notebooks/img/sorted_food101_e20_img512_frac0.1.jpg)\n",
    "\n",
    "\n",
    "![](../runs/classify/sorted_food101_e50_img224_frac0.1/spaghetti_carbonara/pizza_05.jpg)\n",
    "\n",
    "### food101_e50_img224_frac1: best accuracy of `97.60%`\n",
    "1/15 image are classified incorrectly:\n",
    "\n",
    "![](img/sorted_food101_e50_img224_frac0.1.jpg)\n",
    "![](img/sorted_food101_e50_img224_frac1.jpg)\n",
    "![](../runs/classify/sorted_food101_e50_img224_frac1/spaghetti_bolognese/spaghetti_carbonara_05.jpg)\n",
    "\n",
    "### food101_e20_img512_frac0.1: lowest accuracy of `89.47%`\n",
    "2/15 images are classified incorrectly:\n",
    "\n",
    "![](img/sorted_food101_e20_img512_frac0.1.jpg)\n",
    "![](../runs/classify/sorted_food101_e20_img512_frac0.1/spaghetti_bolognese/spaghetti_carbonara_05.jpg)\n",
    "![](../runs/classify/sorted_food101_e20_img512_frac0.1/spaghetti_carbonara/pizza_01.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
