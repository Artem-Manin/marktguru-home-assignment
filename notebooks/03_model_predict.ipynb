{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b148d1",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db2e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5fc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_YAML = Path(\"../data/silver/\")  # point to your dataset.yaml\n",
    "BASE_MODEL = \"yolov8n-cls.pt\"\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 512\n",
    "FRACTION = 1\n",
    "BATCH = 16\n",
    "DEVICE = \"cpu\"\n",
    "PROJECT_PATH = Path(\"../runs/classify\")\n",
    "\n",
    "CLASSES = {\n",
    "    \"pizza\": 76,\n",
    "    \"spaghetti_bolognese\": 90,\n",
    "    \"spaghetti_carbonara\": 91,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b91827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/base_model\u001b[0m\n",
      "002620_76_pizza.jpg: pizza (0.99)\n",
      "002667_76_pizza.jpg: pizza (0.86)\n",
      "002673_76_pizza.jpg: pizza (1.00)\n",
      "002610_76_pizza.jpg: pizza (0.72)\n",
      "002675_76_pizza.jpg: pizza (0.96)\n",
      "002650_76_pizza.jpg: pizza (0.98)\n",
      "002577_76_pizza.jpg: pizza (0.96)\n",
      "002504_76_pizza.jpg: pizza (0.99)\n",
      "025088_90_spaghetti_bolognese.jpg: crayfish (0.91)\n",
      "025101_90_spaghetti_bolognese.jpg: carbonara (0.38)\n",
      "025187_90_spaghetti_bolognese.jpg: carbonara (0.80)\n",
      "025023_90_spaghetti_bolognese.jpg: plate (0.68)\n",
      "025036_90_spaghetti_bolognese.jpg: plate (0.29)\n",
      "025201_90_spaghetti_bolognese.jpg: carbonara (1.00)\n",
      "025011_90_spaghetti_bolognese.jpg: carbonara (1.00)\n",
      "025068_90_spaghetti_bolognese.jpg: plate (0.50)\n",
      "022289_91_spaghetti_carbonara.jpg: carbonara (0.95)\n",
      "022254_91_spaghetti_carbonara.jpg: carbonara (1.00)\n",
      "022257_91_spaghetti_carbonara.jpg: carbonara (0.99)\n",
      "022410_91_spaghetti_carbonara.jpg: carbonara (1.00)\n",
      "022473_91_spaghetti_carbonara.jpg: carbonara (1.00)\n",
      "022450_91_spaghetti_carbonara.jpg: carbonara (0.98)\n",
      "022428_91_spaghetti_carbonara.jpg: carbonara (0.98)\n",
      "022405_91_spaghetti_carbonara.jpg: carbonara (0.78)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(BASE_MODEL)\n",
    "random.seed(42)\n",
    "N = 8 \n",
    "subset = []\n",
    "for cls in CLASSES.keys():\n",
    "    cls_dir = Path(DATASET_YAML) / \"val\" / cls\n",
    "    all_imgs = list(cls_dir.glob(\"*.jpg\"))\n",
    "    if len(all_imgs) >= N:\n",
    "        subset.extend(random.sample(all_imgs, N))\n",
    "    else:\n",
    "        subset.extend(all_imgs)\n",
    "results = model.predict(source=subset, imgsz=IMG_SIZE, device=DEVICE, save=True, verbose=False, project=PROJECT_PATH, name=\"food101_base_model\",exist_ok=True)\n",
    "for r in results:\n",
    "    fname = Path(r.path).name\n",
    "    pred_class = r.names[r.probs.top1]\n",
    "    conf = r.probs.top1conf.item()\n",
    "    print(f\"{fname}: {pred_class} ({conf:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c288e2",
   "metadata": {},
   "source": [
    "Pizza and spaghetti carbonara are recognized almost perfectly.\n",
    "Spaghetti bolognese is missing as a class - confused often with carbonara."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f1299",
   "metadata": {},
   "source": [
    "### Fine-tune model with food101 data\n",
    "\n",
    "The complete set consists of 750 images for training and 250 images for validation in each of three classes.\n",
    "\n",
    "Eight models will be trained for each constellation of:\n",
    "- two epoch values: 20 and 50,\n",
    "- two images sizes: 224 (standard for Yolo) and 512 (images from Hugging Face)\n",
    "- two dataset lengths: 75 and 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â–¶ï¸ food101_e50_img512_frac0.1\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.201 ğŸš€ Python-3.11.13 torch-2.8.0+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/silver, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=food101_e50_img512_frac0.1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=../runs/classify, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac0.1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /workspaces/marktguru-home-assignment/data/silver/train... found 2250 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /workspaces/marktguru-home-assignment/data/silver/val... found 750 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 130.2Â±224.4 MB/s, size: 50.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspaces/marktguru-home-assignment/data/silver/train... 225 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 381.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 100.0Â±109.2 MB/s, size: 45.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspaces/marktguru-home-assignment/data/silver/val... 750 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 750/750 1.3Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac0.1\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/50         0G     0.6621          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.3it/s 46.9s1.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 48.0s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/50         0G    0.08859          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.9s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 45.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/50         0G   0.008495          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.8s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 45.7s2.0ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/50         0G   0.001058          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.3s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 45.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/50         0G   0.000381          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.5s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.9s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/50         0G  0.0001381          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.1s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/50         0G  9.429e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.9s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.0s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/50         0G   6.31e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.1s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/50         0G  4.467e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.6s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.5s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/50         0G  4.181e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.8s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/50         0G   3.34e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.6s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.2s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/50         0G  2.955e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.3s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.8s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/50         0G  3.566e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.4s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 43.7s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/50         0G  2.994e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.3s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/50         0G  2.906e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.2s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 43.7s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/50         0G  3.473e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.5s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.7it/s 35.5s1.5ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/50         0G  2.969e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.0s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.0s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/50         0G  2.449e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.4s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.0s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/50         0G   2.44e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.8s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.1s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/50         0G   2.98e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.0s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.8s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/50         0G  2.816e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.0s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/50         0G  2.509e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.1s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.0s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/50         0G  2.728e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.5s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/50         0G  3.866e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.7s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/50         0G  2.644e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.0s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.4s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/50         0G  2.472e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.1s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.6s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/50         0G  2.762e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.6s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.7s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/50         0G  1.989e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 38.9s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.1s1.8ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/50         0G   3.21e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 39.7s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.2s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/50         0G   2.42e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.0s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.4s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      31/50         0G  1.955e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.5s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.5s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      32/50         0G  2.547e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.1s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      33/50         0G  2.391e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.7s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 43.6s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      34/50         0G   2.18e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.7s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.2s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      35/50         0G  2.047e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.3s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.4s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      36/50         0G  3.359e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.9s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 45.9s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      37/50         0G  1.871e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.2s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 45.2s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      38/50         0G  1.751e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.5s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      39/50         0G  2.268e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.1s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      40/50         0G   2.31e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.6s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.1s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      41/50         0G  2.269e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.0s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 43.8s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      42/50         0G  2.463e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.2s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 43.8s2.0ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      43/50         0G  2.357e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.0s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.6s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      44/50         0G  1.656e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.3s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.5s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      45/50         0G  2.224e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 40.8s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.6s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      46/50         0G  1.744e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.4s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.3s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      47/50         0G  2.049e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.2s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.6s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      48/50         0G  3.739e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.3it/s 43.1s0.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.5s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      49/50         0G  2.063e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 42.6s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.8s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      50/50         0G  2.382e-05          1        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 0.4it/s 41.9s0.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.0s1.9ss\n",
      "                   all      0.333          1\n",
      "\n",
      "50 epochs completed in 1.183 hours.\n",
      "Optimizer stripped from /workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac0.1/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac0.1/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac0.1/weights/best.pt...\n",
      "Ultralytics 8.3.201 ğŸš€ Python-3.11.13 torch-2.8.0+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /workspaces/marktguru-home-assignment/data/silver/train... found 2250 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /workspaces/marktguru-home-assignment/data/silver/val... found 750 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.7it/s 35.6s1.5ss\n",
      "                   all      0.333          1\n",
      "Speed: 0.0ms preprocess, 39.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac0.1\u001b[0m\n",
      "â±ï¸ runtime: 71.703 min\n",
      "\n",
      "â–¶ï¸ food101_e50_img512_frac1\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.201 ğŸš€ Python-3.11.13 torch-2.8.0+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/silver, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=food101_e50_img512_frac1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=../runs/classify, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /workspaces/marktguru-home-assignment/data/silver/train... found 2250 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /workspaces/marktguru-home-assignment/data/silver/val... found 750 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "Transferred 158/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1727.1Â±686.9 MB/s, size: 50.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspaces/marktguru-home-assignment/data/silver/train... 2250 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2250/2250 357.0it/s 6.3s0.4s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspaces/marktguru-home-assignment/data/silver/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2209.9Â±688.1 MB/s, size: 45.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspaces/marktguru-home-assignment/data/silver/val... 750 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 750/750 417.6Kit/s 0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/food101_e50_img512_frac1\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/50         0G      2.969         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.3it/s 6:472.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 43.7s1.9ss\n",
      "                   all      0.895          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/50         0G     0.3908         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:412.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.4s1.8ss\n",
      "                   all        0.9          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/50         0G     0.3295         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:422.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.5it/s 44.2s1.9ss\n",
      "                   all      0.903          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.2505         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.3it/s 6:502.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 39.6s1.7ss\n",
      "                   all      0.956          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/50         0G     0.2548         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.3it/s 6:442.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.7s1.8ss\n",
      "                   all      0.952          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/50         0G     0.2373         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:422.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 38.7s1.7ss\n",
      "                   all      0.941          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/50         0G     0.2016         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:382.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 39.9s1.7ss\n",
      "                   all      0.949          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/50         0G     0.1823         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.3it/s 6:482.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.6s1.8ss\n",
      "                   all      0.907          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.1628         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:432.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 41.3s1.8ss\n",
      "                   all      0.955          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.1713         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:402.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.0s1.8ss\n",
      "                   all      0.941          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.1427         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:392.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 42.0s1.8ss\n",
      "                   all      0.957          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/50         0G       0.14         10        512: 100% â”â”â”â”â”â”â”â”â”â”â”â” 141/141 0.4it/s 6:392.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 0.6it/s 40.7s1.7ss\n",
      "                   all      0.947          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.1108         16        512: 2% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3/141 0.2it/s 11.5s<10:07"
     ]
    }
   ],
   "source": [
    "model = YOLO(BASE_MODEL)\n",
    "#EPOCHS_LIST   = [20, 50]\n",
    "EPOCHS_LIST   = [50]\n",
    "#IMG_SIZE_LIST = [224,512]\n",
    "IMG_SIZE_LIST = [512]\n",
    "FRACTIONS     = [0.1, 1]\n",
    "for epochs in EPOCHS_LIST:\n",
    "    for img in IMG_SIZE_LIST:\n",
    "        for frac in FRACTIONS:\n",
    "            name = f\"food101_e{epochs}_img{img}_frac{frac}\"\n",
    "            print(f\"\\nâ–¶ï¸ {name}\")\n",
    "            t0 = time.time()\n",
    "            res = model.train(\n",
    "                data=str(DATASET_YAML),\n",
    "                epochs=epochs,\n",
    "                imgsz=img,\n",
    "                batch=BATCH,\n",
    "                device=DEVICE,\n",
    "                project=str(PROJECT_PATH),\n",
    "                name=name,\n",
    "                exist_ok=True,\n",
    "                fraction=frac,\n",
    "                verbose=False\n",
    "            )\n",
    "            runtime_min = round((time.time() - t0) / 60, 3)\n",
    "            (PROJECT_PATH / name / \"summary.json\").write_text(\n",
    "                json.dumps({\"runtime_min\": runtime_min}, ensure_ascii=False)\n",
    "            )\n",
    "            print(f\"â±ï¸ runtime: {runtime_min} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16ab2f",
   "metadata": {},
   "source": [
    "### Gather statistics of model training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32c5550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "def pick_col(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols: return c\n",
    "    return None\n",
    "for run in sorted(PROJECT_PATH.glob(\"food101_e*_img*_frac*\")):\n",
    "    args_p     = run / \"args.yaml\"\n",
    "    results_p  = run / \"results.csv\"\n",
    "    summary_p  = run / \"summary.json\"\n",
    "    best_pt_p  = run / \"weights\" / \"best.pt\"\n",
    "    if not results_p.exists():\n",
    "        continue\n",
    "    args = {}\n",
    "    if args_p.exists():\n",
    "        args = yaml.safe_load(args_p.read_text())\n",
    "    df = pd.read_csv(results_p)\n",
    "    top1_col = pick_col(df.columns, [\"metrics/accuracy_top1\", \"top1\", \"val/top1\"])\n",
    "    if top1_col is None:\n",
    "        best_top1 = float(\"nan\")\n",
    "    else:\n",
    "        best_row_idx = df[top1_col].idxmax()\n",
    "        best_top1 = float(df.loc[best_row_idx, top1_col])\n",
    "    runtime_min = None\n",
    "    if summary_p.exists():\n",
    "        runtime_min = json.loads(summary_p.read_text()).get(\"runtime_min\")\n",
    "    rows.append({\n",
    "        \"run_dir\": str(run.resolve()),\n",
    "        \"epochs\": args.get(\"epochs\"),\n",
    "        \"img_size\": args.get(\"imgsz\") or args.get(\"img_size\"),\n",
    "        \"fraction\": args.get(\"fraction\"),\n",
    "        \"top1_acc_best\": round(best_top1, 4) if best_top1 == best_top1 else None,  # NaN guard\n",
    "        \"runtime_min\": runtime_min,\n",
    "        \"best_weights\": str(best_pt_p.resolve()) if best_pt_p.exists() else None,\n",
    "    })\n",
    "stats = pd.DataFrame(rows)\n",
    "stats_path = PROJECT_PATH / \"experiment_stats.csv\"\n",
    "stats.to_csv(stats_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1bc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e36ce_row0_col3, #T_e36ce_row3_col4 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "#T_e36ce_row0_col4, #T_e36ce_row3_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e36ce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e36ce_level0_col0\" class=\"col_heading level0 col0\" >epochs</th>\n",
       "      <th id=\"T_e36ce_level0_col1\" class=\"col_heading level0 col1\" >img_size</th>\n",
       "      <th id=\"T_e36ce_level0_col2\" class=\"col_heading level0 col2\" >fraction</th>\n",
       "      <th id=\"T_e36ce_level0_col3\" class=\"col_heading level0 col3\" >top1_acc_best</th>\n",
       "      <th id=\"T_e36ce_level0_col4\" class=\"col_heading level0 col4\" >runtime_min</th>\n",
       "      <th id=\"T_e36ce_level0_col5\" class=\"col_heading level0 col5\" >model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e36ce_row0_col0\" class=\"data row0 col0\" >20</td>\n",
       "      <td id=\"T_e36ce_row0_col1\" class=\"data row0 col1\" >224</td>\n",
       "      <td id=\"T_e36ce_row0_col2\" class=\"data row0 col2\" >0.100000</td>\n",
       "      <td id=\"T_e36ce_row0_col3\" class=\"data row0 col3\" >0.333300</td>\n",
       "      <td id=\"T_e36ce_row0_col4\" class=\"data row0 col4\" >6.230000</td>\n",
       "      <td id=\"T_e36ce_row0_col5\" class=\"data row0 col5\" >food101_e20_img224_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e36ce_row1_col0\" class=\"data row1 col0\" >20</td>\n",
       "      <td id=\"T_e36ce_row1_col1\" class=\"data row1 col1\" >224</td>\n",
       "      <td id=\"T_e36ce_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "      <td id=\"T_e36ce_row1_col3\" class=\"data row1 col3\" >0.972000</td>\n",
       "      <td id=\"T_e36ce_row1_col4\" class=\"data row1 col4\" >28.919000</td>\n",
       "      <td id=\"T_e36ce_row1_col5\" class=\"data row1 col5\" >food101_e20_img224_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e36ce_row2_col0\" class=\"data row2 col0\" >20</td>\n",
       "      <td id=\"T_e36ce_row2_col1\" class=\"data row2 col1\" >512</td>\n",
       "      <td id=\"T_e36ce_row2_col2\" class=\"data row2 col2\" >0.100000</td>\n",
       "      <td id=\"T_e36ce_row2_col3\" class=\"data row2 col3\" >0.894700</td>\n",
       "      <td id=\"T_e36ce_row2_col4\" class=\"data row2 col4\" >28.893000</td>\n",
       "      <td id=\"T_e36ce_row2_col5\" class=\"data row2 col5\" >food101_e20_img512_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e36ce_row3_col0\" class=\"data row3 col0\" >20</td>\n",
       "      <td id=\"T_e36ce_row3_col1\" class=\"data row3 col1\" >512</td>\n",
       "      <td id=\"T_e36ce_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "      <td id=\"T_e36ce_row3_col3\" class=\"data row3 col3\" >0.980000</td>\n",
       "      <td id=\"T_e36ce_row3_col4\" class=\"data row3 col4\" >158.982000</td>\n",
       "      <td id=\"T_e36ce_row3_col5\" class=\"data row3 col5\" >food101_e20_img512_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e36ce_row4_col0\" class=\"data row4 col0\" >50</td>\n",
       "      <td id=\"T_e36ce_row4_col1\" class=\"data row4 col1\" >224</td>\n",
       "      <td id=\"T_e36ce_row4_col2\" class=\"data row4 col2\" >0.100000</td>\n",
       "      <td id=\"T_e36ce_row4_col3\" class=\"data row4 col3\" >0.917300</td>\n",
       "      <td id=\"T_e36ce_row4_col4\" class=\"data row4 col4\" >14.628000</td>\n",
       "      <td id=\"T_e36ce_row4_col5\" class=\"data row4 col5\" >food101_e50_img224_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e36ce_row5_col0\" class=\"data row5 col0\" >50</td>\n",
       "      <td id=\"T_e36ce_row5_col1\" class=\"data row5 col1\" >224</td>\n",
       "      <td id=\"T_e36ce_row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "      <td id=\"T_e36ce_row5_col3\" class=\"data row5 col3\" >0.976000</td>\n",
       "      <td id=\"T_e36ce_row5_col4\" class=\"data row5 col4\" >73.864000</td>\n",
       "      <td id=\"T_e36ce_row5_col5\" class=\"data row5 col5\" >food101_e50_img224_frac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e36ce_row6_col0\" class=\"data row6 col0\" >50</td>\n",
       "      <td id=\"T_e36ce_row6_col1\" class=\"data row6 col1\" >512</td>\n",
       "      <td id=\"T_e36ce_row6_col2\" class=\"data row6 col2\" >0.100000</td>\n",
       "      <td id=\"T_e36ce_row6_col3\" class=\"data row6 col3\" >0.940000</td>\n",
       "      <td id=\"T_e36ce_row6_col4\" class=\"data row6 col4\" >71.703000</td>\n",
       "      <td id=\"T_e36ce_row6_col5\" class=\"data row6 col5\" >food101_e50_img512_frac0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e36ce_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e36ce_row7_col0\" class=\"data row7 col0\" >50</td>\n",
       "      <td id=\"T_e36ce_row7_col1\" class=\"data row7 col1\" >512</td>\n",
       "      <td id=\"T_e36ce_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "      <td id=\"T_e36ce_row7_col3\" class=\"data row7 col3\" >0.970700</td>\n",
       "      <td id=\"T_e36ce_row7_col4\" class=\"data row7 col4\" >nan</td>\n",
       "      <td id=\"T_e36ce_row7_col5\" class=\"data row7 col5\" >food101_e50_img512_frac1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ef76b9e1110>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(PROJECT_PATH / \"experiment_stats.csv\")\n",
    "stats[\"model\"] = stats[\"best_weights\"].apply(lambda p: Path(p).parent.parent.name)\n",
    "stats_subset = stats.drop(columns=[\"run_dir\", \"best_weights\"])\n",
    "(\n",
    "    stats_subset.style\n",
    "    .highlight_max(subset=['top1_acc_best'], color='lightgreen')\n",
    "    .highlight_min(subset=['top1_acc_best'], color='lightcoral')\n",
    "    .highlight_max(subset=['runtime_min'], color='lightcoral')\n",
    "    .highlight_min(subset=['runtime_min'], color='lightgreen')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d120f",
   "metadata": {},
   "source": [
    "### Inaccurate and long-training models\n",
    "\n",
    "1. A model with minimum parameters `food101_e20_img224_frac0.1` shows a very poor accuracy result - `0.33`<br>\n",
    "[Confusion matrix](../runs/classify/food101_e20_img224_frac0.1/confusion_matrix_normalized.png) shows that actually all the dishes were put into one class - pizza.<br>\n",
    "A very low runtime should not distract here - we will not use this model and remove from futher analysis.\n",
    "2. On the other side of the spectrum, there are models with the best accuracy (`> 98%`), but with also the longest runtime (`> 2 hours`):\n",
    "    - `food101_e20_img512_frac1`\n",
    "    - `food101_e50_img512_frac1`\n",
    "\n",
    "    Let's remove them as well.\n",
    "\n",
    "3. The remaining five models lie in the range `89-97%` for accurace and `14-74 minutes` for runtime, which we find acceptable.\n",
    "4. Let's add for them some efficiency metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_filt = stats_subset[~stats_subset[\"model\"].isin([\"food101_e20_img224_frac0.1\", \"food101_e20_img512_frac1\",\"food101_e50_img512_frac1\"])]\n",
    "stats_subset[\"efficiency\"] = stats_subset[\"top1_acc_best\"] / stats_subset[\"runtime_min\"]\n",
    "eff = stats_subset[\"efficiency\"]\n",
    "stats_subset[\"efficiency_norm\"] = ((eff - eff.min()) / (eff.max() - eff.min())).round(2)\n",
    "(\n",
    "    stats_subset.style\n",
    "    .highlight_max(subset=['top1_acc_best'], color='lightgreen')\n",
    "    .highlight_min(subset=['top1_acc_best'], color='lightcoral')\n",
    "    .highlight_max(subset=['runtime_min'], color='lightcoral')\n",
    "    .highlight_min(subset=['runtime_min'], color='lightgreen')\n",
    "    .highlight_max(subset=['efficiency_norm'], color='lightgreen')\n",
    "    .highlight_min(subset=['efficiency_norm'], color='lightcoral')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d223c",
   "metadata": {},
   "source": [
    "### Impact of each parameter change on precision and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8dc21387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>target</th>\n",
       "      <th>fromâ†’to</th>\n",
       "      <th>abs_change</th>\n",
       "      <th>rel_change_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epochs</td>\n",
       "      <td>runtime_min</td>\n",
       "      <td>20â†’50</td>\n",
       "      <td>32.0510</td>\n",
       "      <td>146.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fraction</td>\n",
       "      <td>runtime_min</td>\n",
       "      <td>0.1â†’1.0</td>\n",
       "      <td>70.6713</td>\n",
       "      <td>406.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_size</td>\n",
       "      <td>runtime_min</td>\n",
       "      <td>224â†’512</td>\n",
       "      <td>69.9337</td>\n",
       "      <td>401.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>epochs</td>\n",
       "      <td>top1_acc_best</td>\n",
       "      <td>20â†’50</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>44.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fraction</td>\n",
       "      <td>top1_acc_best</td>\n",
       "      <td>0.1â†’1.0</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>52.7075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img_size</td>\n",
       "      <td>top1_acc_best</td>\n",
       "      <td>224â†’512</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>42.7975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      param         target  fromâ†’to  abs_change  rel_change_%\n",
       "0    epochs    runtime_min    20â†’50     32.0510      146.1300\n",
       "1  fraction    runtime_min  0.1â†’1.0     70.6713      406.4600\n",
       "2  img_size    runtime_min  224â†’512     69.9337      401.2333\n",
       "3    epochs  top1_acc_best    20â†’50      0.1560       44.9350\n",
       "4  fraction  top1_acc_best  0.1â†’1.0      0.2034       52.7075\n",
       "5  img_size  top1_acc_best  224â†’512      0.1467       42.7975"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = stats_subset.copy()\n",
    "\n",
    "comparisons = []\n",
    "\n",
    "# Epochs effect (control img_size + fraction)\n",
    "for (img, frac), group in df.groupby([\"img_size\", \"fraction\"]):\n",
    "    if {20, 50}.issubset(set(group[\"epochs\"])):\n",
    "        base = group[group[\"epochs\"] == 20].iloc[0]\n",
    "        alt  = group[group[\"epochs\"] == 50].iloc[0]\n",
    "        for target in [\"top1_acc_best\", \"runtime_min\"]:\n",
    "            diff_abs = alt[target] - base[target]\n",
    "            diff_rel = diff_abs / base[target] * 100\n",
    "            comparisons.append({\n",
    "                \"param\": \"epochs\",\n",
    "                \"control\": f\"img={img}, frac={frac}\",\n",
    "                \"fromâ†’to\": \"20â†’50\",\n",
    "                \"target\": target,\n",
    "                \"abs_change\": round(diff_abs, 4),\n",
    "                \"rel_change_%\": round(diff_rel, 2)\n",
    "            })\n",
    "\n",
    "# Img_size effect (control epochs + fraction)\n",
    "for (ep, frac), group in df.groupby([\"epochs\", \"fraction\"]):\n",
    "    if {224, 512}.issubset(set(group[\"img_size\"])):\n",
    "        base = group[group[\"img_size\"] == 224].iloc[0]\n",
    "        alt  = group[group[\"img_size\"] == 512].iloc[0]\n",
    "        for target in [\"top1_acc_best\", \"runtime_min\"]:\n",
    "            diff_abs = alt[target] - base[target]\n",
    "            diff_rel = diff_abs / base[target] * 100\n",
    "            comparisons.append({\n",
    "                \"param\": \"img_size\",\n",
    "                \"control\": f\"epochs={ep}, frac={frac}\",\n",
    "                \"fromâ†’to\": \"224â†’512\",\n",
    "                \"target\": target,\n",
    "                \"abs_change\": round(diff_abs, 4),\n",
    "                \"rel_change_%\": round(diff_rel, 2)\n",
    "            })\n",
    "\n",
    "# Fraction effect (control epochs + img_size)\n",
    "for (ep, img), group in df.groupby([\"epochs\", \"img_size\"]):\n",
    "    if {0.1, 1.0}.issubset(set(group[\"fraction\"])):\n",
    "        base = group[group[\"fraction\"] == 0.1].iloc[0]\n",
    "        alt  = group[group[\"fraction\"] == 1.0].iloc[0]\n",
    "        for target in [\"top1_acc_best\", \"runtime_min\"]:\n",
    "            diff_abs = alt[target] - base[target]\n",
    "            diff_rel = diff_abs / base[target] * 100\n",
    "            comparisons.append({\n",
    "                \"param\": \"fraction\",\n",
    "                \"control\": f\"epochs={ep}, img={img}\",\n",
    "                \"fromâ†’to\": \"0.1â†’1.0\",\n",
    "                \"target\": target,\n",
    "                \"abs_change\": round(diff_abs, 4),\n",
    "                \"rel_change_%\": round(diff_rel, 2)\n",
    "            })\n",
    "\n",
    "comp_df = pd.DataFrame(comparisons)\n",
    "comp_df = comp_df.sort_values(by=[\"param\", \"target\", \"control\"]).reset_index(drop=True)\n",
    "summary = (\n",
    "    comp_df\n",
    "    .groupby([\"param\", \"target\", \"fromâ†’to\"], as_index=False)[[\"abs_change\", \"rel_change_%\"]]\n",
    "    .mean()\n",
    "    .round(4)\n",
    ")\n",
    "summary.sort_values(by=[\"target\", \"param\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b37c5b",
   "metadata": {},
   "source": [
    "### Predict custom uploaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086c1a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 models\n",
      "â–¶ï¸ Predicting with food101_e20_img224_frac0.1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e20_img224_frac0.1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e20_img224_frac0.1\n",
      "â–¶ï¸ Predicting with food101_e50_img512_frac1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e50_img512_frac1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e50_img512_frac1\n",
      "â–¶ï¸ Predicting with food101_e50_img224_frac1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e50_img224_frac1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e50_img224_frac1\n",
      "â–¶ï¸ Predicting with food101_e50_img512_frac0.1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e50_img512_frac0.1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e50_img512_frac0.1\n",
      "â–¶ï¸ Predicting with food101_e50_img224_frac0.1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e50_img224_frac0.1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e50_img224_frac0.1\n",
      "â–¶ï¸ Predicting with food101_e20_img512_frac1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e20_img512_frac1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e20_img512_frac1\n",
      "â–¶ï¸ Predicting with food101_e20_img224_frac1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e20_img224_frac1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e20_img224_frac1\n",
      "â–¶ï¸ Predicting with food101_e20_img512_frac0.1\n",
      "Results saved to \u001b[1m/workspaces/marktguru-home-assignment/runs/classify/predict_food101_e20_img512_frac0.1\u001b[0m\n",
      "âœ… Labeled predictions sorted to ../runs/classify/sorted_food101_e20_img512_frac0.1\n"
     ]
    }
   ],
   "source": [
    "upload_dir = Path(DATASET_YAML) / \"upload\"\n",
    "models = list(PROJECT_PATH.glob(\"food101_*/weights/best.pt\"))\n",
    "print(f\"Found {len(models)} models\")\n",
    "\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "\n",
    "for m in models:\n",
    "    exp_name = m.parent.parent.name  # e.g. food101_e20_img224_frac0.1\n",
    "    print(f\"â–¶ï¸ Predicting with {exp_name}\")\n",
    "\n",
    "    # parse imgsz from name (expects \"..._img{N}_...\")\n",
    "    try:\n",
    "        img_size = int(exp_name.split(\"_img\")[1].split(\"_\")[0])\n",
    "    except Exception:\n",
    "        img_size = 224\n",
    "\n",
    "    model = YOLO(m)\n",
    "    results = model.predict(\n",
    "        source=upload_dir,\n",
    "        imgsz=img_size,\n",
    "        device=\"cpu\",\n",
    "        save=True,              # writes labeled images into project/name/\n",
    "        project=PROJECT_PATH,\n",
    "        name=f\"predict_{exp_name}\",\n",
    "        exist_ok=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # sort the **labeled** images into class folders\n",
    "    sorted_dir = PROJECT_PATH / f\"sorted_{exp_name}\"\n",
    "    sorted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for r in results:\n",
    "        pred_class = r.names[r.probs.top1]\n",
    "\n",
    "        # where Ultralytics saved this labeled image\n",
    "        save_dir = Path(r.save_dir)                # predict folder for this run\n",
    "        src_name = Path(r.path).name               # original filename\n",
    "        labeled_path = save_dir / src_name         # typical case (same name)\n",
    "\n",
    "        if not labeled_path.exists():\n",
    "            # fallback: find any image starting with the same stem (covers suffix variants)\n",
    "            stem = Path(src_name).stem\n",
    "            cand = []\n",
    "            for ext in IMAGE_EXTS:\n",
    "                cand += list(save_dir.glob(f\"{stem}*{ext}\"))\n",
    "            labeled_path = cand[0] if cand else None\n",
    "\n",
    "        # target folder by predicted class\n",
    "        target_dir = sorted_dir / pred_class\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if labeled_path and labeled_path.exists():\n",
    "            shutil.copy(labeled_path, target_dir / labeled_path.name)\n",
    "        else:\n",
    "            # fallback: copy original if labeled not found\n",
    "            shutil.copy(r.path, target_dir / src_name)\n",
    "\n",
    "    print(f\"âœ… Labeled predictions sorted to {sorted_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
